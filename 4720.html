<!DOCTYPE html>
<!-- saved from url=(0056)https://index.mirasmart.com/ISMRM2019/PDFfiles/4720.html -->
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><title>

</title>
     
    <script type="text/javascript" src="./4720_files/jquery.js.download"></script>
    

    <script src="./4720_files/MathJax.js.download" id=""></script>
    <link type="text/css" rel="stylesheet" href="./4720_files/css"><link type="text/css" rel="Stylesheet" href="./4720_files/bootstrap.min.css"><link type="text/css" rel="Stylesheet" href="./4720_files/bootstrap-theme.min.css"><link type="text/css" rel="Stylesheet" href="./4720_files/viewSubmissions.css"><meta name="viewport" content="width=device-width, initial-scale=1">  


    <script type="text/x-mathjax-config;executed=true">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$$$','$$$'], ["\\(","\\)"] ],
          processEscapes: true
        }
      });
    </script>

    
<style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style></head>
<body style=""><div id="MathJax_Message" style="display: none;"></div>
    
        <div id="SubmissionViewBreadCrumbWrapper"> </div>         
        <div id="contentWrapper" class="MainContentWrapper">   
           
    

	
    





<div class="col-lg-8 col-md-12 col-xm-12"> 
    <h3>
        <span id="ctl00_MainContent_ctl00_lblSubmissionID">4720</span>
    </h3>
    <span id="ctl00_MainContent_ctl00_submissionTitle" class="submissionTitle">Performant summative 3D rendering of voxel-wise MRF segmentation data</span>
    <div id="ctl00_MainContent_ctl00_autherBlock">        
        <div id="ctl00_MainContent_ctl00_AuthorsAndAffiliationsBlock_divBlockContainer" class="AffiliationBlockContainer">
    <div id="affAuthers" class="affAuthers">Andrew Dupuis<sup>1,2</sup>, Debra McGivney<sup>3</sup>, Rasim Boyacioglu<sup>3</sup>, Dan Ma<sup>3</sup>, Anagha Deshmane<sup>4</sup>, and Mark A Griswold<sup>1,2,3</sup></div><i><div id="affOther" class="affOther"><br><sup>1</sup>Biomedical Engineering, Case Western Reserve University, Cleveland, OH, United States, <sup>2</sup>Interactive Commons, Case Western Reserve University, Cleveland, OH, United States, <sup>3</sup>Department of Radiology, School of Medicine, Case Western Reserve University, Cleveland, OH, United States, <sup>4</sup>Max Planck Institute for Biological Cybernetics, Tübingen, Germany</div></i>
</div>


    </div>

    <div id="ctl00_MainContent_ctl00_sectionsWrapper" class="sectionsWrapper">
	        
    <div class="divSectionBlock"><h3>Synopsis</h3><p class="synopsis">Visualization
of Magnetic Resonance Fingerprinting segmented data presents significant
difficulty because of the abstraction from the usual appearance and contrast of
MR images. We present a method of rendering any probability-based tissue
fraction partial volume ROIs in three dimensions using additive voxelized
volumetric rendering as a form of segmentation. Datasets consist of n groups of segmented maps with each voxel representing the probability of a given tissue converted
into 3D textures usable by the GPU to perform raymarched additive rendering.
This allows for different tissue classifications within the dataset to be faded
in and out with minimal human involvement.</p></div><div class="divSectionBlock"><h3><b>Purpose</b></h3><p>Multidimensional
segmentation for visualization is a computation and time intensive process.
However, recent research in Magnetic Resonance Fingerprinting (MRF) has put
emphasis on classifying groups of voxels based on quantitative data collected
during the acquisition. Using these “confidence of classification” type maps
for 3D segmentation is a logical next step: by using such maps to control a
voxel’s opacity (alpha) in a rendering, immediate visualization of different
tissues is possible.</p><p>Three-dimensional
visualizations of data have value due to the ability to look beyond a single
plane within an acquired dataset. When combined with the ability to control the
opacity of different groups of tissues, such visualizations gain even more
diagnostic and educational relevance. We aim to provide radiologists and
surgeons the ability to rapidly identify the general location and size of a
pathology in an intuitive way without increasing the amount of manual
segmentation or ROI generation required.  </p></div><div class="divSectionBlock"><h3><b>Methods</b></h3><p>MRF
segmented data are generated from MRF acquisitions using an automated
classification technique – here, we tested the system using data created via dictionary-based
segmentation [1],
Multicomponent Bayesian Estimation[2], and Independent Component
Analysis (ICA) [3].
Each classification methodology outputs maps containing normalized percent
contributions of a specific classification, with the sum of all maps
corresponding from a single voxel equaling one.</p><p>Each
map’s  slices are processed to generate a 2D Texture Array used for voxel lookups on the GPU. These arrays each represent one tissue classification
type. A base color and linear weighting factor are assigned to each 2D Texture
Array, then all texture arrays are combined into a master 3D Color Texture as
well as a master 3D Gradient texture containing calculated local gradient data.
Together, these 3D textures allow for shaded and colored renderings of the
MR datasets. </p><p>









The
user controls the component rendering weights, allowing  modification of each segmentation's opacity. This allows the user to fade in and fade out
different regions and tissues in the image in near real-time.The user also controls the color assigned to each segment, letting them place emphasis on
regions they want to demonstrate to a peer, or serving as a reminder about a
problematic area. </p><p>Rendering
is performed with an optimized raymarching system created for efficiency on
mobile processors.[4]
Because the additive rendering approach generates visualizations that approximate
surfaces within the dataset, modifications were made to the renderer to enable Phong
lighting[5]   to give the user the ability to add
shadow and improve surface contrast dynamically. Lighting position, color, and
intensity are all variable in real time.</p></div><div class="divSectionBlock"><h3>Results</h3><p>The renderer was performant on both desktop computers and high end mobile hardware, with adequate framerates
possible on even commodity smartphones (Samsung Galaxy S9+).  Effective visualizations were generated for
all three tested segmentation approaches. All datasets were collected with
matrix size 235x256x120, with 1.2mm isotropic voxels. </p><p>The segmentation that most closely matches traditional
tissue classifications is generated with the dictionary-based segmentation.
However, this approach requires the most human intervention during the
segmentation process because the user must draw and define ROIs for each
desired tissue type. Since the dictionary-based segmentations had predefined
tissue types for white matter, grey matter, fat, and CSF, the datasets from the
dictionary-based segmentations were easy to understand and interpret. A
rendering of the dictionary-based approach is shown in Figure 1.
</p><p>
The Bayesian approach created clear benefits in the
form of direct visualization of pathology: thanks to its sensitivity to local
groups of tissues, this approach created maps that directly visualize a peritumoral
mass and the surrounding vasculature. </p><p>These segmentations required no human
input, and create clear visualization of the scale and location of the tumor. 

The ICA approach
generated maps that similarly visualized
structures with clear component distinction that would not be evident or separable
without more involved classical segmentation and polygonization – notably, CSF
and vasculature are visible in Figures 3 and 4.</p></div><div class="divSectionBlock"><h3>Discussion</h3>Rapid visualization of specific three dimensional tissue
structures without extensive human intervention would be a significant advance
in MR, as it could potentially increase our ability to communicate 3D
information about disease. This work demonstrates that emerging MRF-based
tissue classification techniques, when combined with rendering approaches that
leverage voxel-specific characteristics like opacity, are beginning to produce
maps that can be used for useful unsupervised segmentation without reliance on
deep learning techniques. Such classifications and visualizations promise to be
robust and extensible. Moreover, as the rendering approach described is
additive, all of the mentioned segmentation approaches can be used
constructively to create custom segmentations and visualizations that are
highly specific. Because these processing and rendering steps don’t require any
specialized hardware, we believe that these methods could impact a wide range
of diagnostic situations in MRI.</div><div class="divSectionBlock"><h3>Acknowledgements</h3>Siemens Healthcare, R01EB018108, NSF
1563805, R01DK098503, and R01HL094557. </div><div class="divSectionBlock"><h3>References</h3><p>[1] Deshmane, A., McGivney, D., Badve, C., Gulani, V. and Griswold, M.A.(2016), Dictionary approach to partial volume estimation with MR Fingerprinting: Validation and application to brain tumor segmentation. ISMRM 2016: 132. </p><p>[2] McGivney, D. , Deshmane, A. , Jiang, Y. , Ma, D.
, Badve, C. , Sloan, A. , Gulani, V. and Griswold, M.A. (2018), Bayesian
estimation of multicomponent relaxation parameters in magnetic resonance
fingerprinting. Magn. Reson. Med, 80: 159-170. doi:10.1002/mrm.27017</p><p>[3] Boyacioglu, R., Ma, D., McGivney, D., Onyewadume, L., Kilinc, O., Badve, C., Gulani, V., and Griswold, M.A. (2017). Dictionary free anatomical segmentation of Magnetic Resonance Fingerprinting brain data with Independent Component Analysis. ISMRM 2017. </p><p>[4] Dupuis, A., Franson, D., Jiang, Y., Mlakar, J., Eastman, H., Gulani, V., Seiberlich, N., and Griswold, M.A. (2017). Collaborative volumetric magnetic resonance image rendering on consumer-grade devices. ISMRM 2017. </p><p>[5] Phong, B. (1975). Illumination for Computer Generated Pictures. Comm. ACM., 18. 6. 311-318.</p><p> </p></div>
</div>
        
</div>
            
<div class="col-lg-3">
        <div id="ctl00_MainContent_ctl00_figures">
        <h3>Figures</h3>
        <div id="ctl00_MainContent_ctl00_figuresWrapper" class="figuresWrapper">
	
        
        <div class="divSectionBlock"><a id="ctl00_MainContent_ctl00_lnkImage_1" class="thumbnail" data-lightbox="figureImages" title="&lt;strong&gt;Figure 1:&lt;/strong&gt; &lt;em&gt;(Click to play animation)&lt;/em&gt; Rendering of a dictionary-based segmenation of MRF data. Yellow
represents the fat segmentation; blue represents white matter; green represents
grey matter; and red represents CSF. The transparency and weighting of each
segmentation is varied to produce different representations of the dataset in
real time.&amp;nbsp;" href="https://index.mirasmart.com/ISMRM2019/PDFfiles/images/4297/ISMRM2019-004297_Fig1.gif" target="_blank"><img src="./4720_files/ISMRM2019-004297_Fig1.gif" border="0" style="text-align:center;"></a><div class="thumbnailCaptions"><strong>Figure 1:</strong> <em>(Click to play animation)</em> Rendering of a dictionary-based segmenation of MRF data. Yellow
represents the fat segmentation; blue represents white matter; green represents
grey matter; and red represents CSF. The transparency and weighting of each
segmentation is varied to produce different representations of the dataset in
real time. </div><br><a id="ctl00_MainContent_ctl00_lnkImage_2" class="thumbnail" data-lightbox="figureImages" title="&lt;strong&gt;Figure 2: &lt;/strong&gt;&lt;em&gt;(Click to play animation)&lt;/em&gt;&amp;nbsp;Rendering of a segmentation generated with
Multicomponent Bayesian analysis. Note that the Bayesian components are
generated not assigned to specific tissue types. The yellow highlights a
Bayesian component sensitive to vasculature; the red represents sensitivity to
the peritumoral mass; the blue represents sensitivity to CSF; and the white
represents incredible sensitivity to the tumor&amp;rsquo;s structural components.&amp;nbsp;" href="https://index.mirasmart.com/ISMRM2019/PDFfiles/images/4297/ISMRM2019-004297_Fig2.gif" target="_blank"><img src="./4720_files/ISMRM2019-004297_Fig2.gif" border="0" style="text-align:center;"></a><div class="thumbnailCaptions"><strong>Figure 2: </strong><em>(Click to play animation)</em> Rendering of a segmentation generated with
Multicomponent Bayesian analysis. Note that the Bayesian components are
generated not assigned to specific tissue types. The yellow highlights a
Bayesian component sensitive to vasculature; the red represents sensitivity to
the peritumoral mass; the blue represents sensitivity to CSF; and the white
represents incredible sensitivity to the tumor’s structural components. </div><br><a id="ctl00_MainContent_ctl00_lnkImage_3" class="thumbnail" data-lightbox="figureImages" title="&lt;strong&gt;Figure 3:&lt;/strong&gt; &lt;em&gt;(Click to play animation)&lt;/em&gt;&amp;nbsp;&amp;nbsp;Rendering demonstrating transparency control of the rendering of an
ICA-based segmentation. Varying the color and weighting of the vasculature
(pink) and the CSF (blue/white) generate visualizations with emphasis on
different elements of the anatomy. This is useful for collaborative discussion
of the dataset or demonstration of anatomy outside of the traditional reading
room.&amp;nbsp;" href="https://index.mirasmart.com/ISMRM2019/PDFfiles/images/4297/ISMRM2019-004297_Fig3.gif" target="_blank"><img src="./4720_files/ISMRM2019-004297_Fig3.gif" border="0" style="text-align:center;"></a><div class="thumbnailCaptions"><strong>Figure 3:</strong> <em>(Click to play animation)</em>  Rendering demonstrating transparency control of the rendering of an
ICA-based segmentation. Varying the color and weighting of the vasculature
(pink) and the CSF (blue/white) generate visualizations with emphasis on
different elements of the anatomy. This is useful for collaborative discussion
of the dataset or demonstration of anatomy outside of the traditional reading
room. </div><br><a id="ctl00_MainContent_ctl00_lnkImage_4" class="thumbnail" data-lightbox="figureImages" title="&lt;strong&gt;Figure 4:&lt;/strong&gt; &lt;em&gt;(Click to play animation)&lt;/em&gt;&amp;nbsp;&amp;nbsp;Rendering of the same ICA-based segmentation as Figure 3, but modified to demonstrate the ability
to &amp;ldquo;slice&amp;rdquo; into the rendering and manipulate the viewpoint in realtime. This
clearly shows the dimensionality of the segmentation.&amp;nbsp;" href="https://index.mirasmart.com/ISMRM2019/PDFfiles/images/4297/ISMRM2019-004297_Fig4.gif" target="_blank"><img src="./4720_files/ISMRM2019-004297_Fig4.gif" border="0" style="text-align:center;"></a><div class="thumbnailCaptions"><strong>Figure 4:</strong> <em>(Click to play animation)</em>  Rendering of the same ICA-based segmentation as Figure 3, but modified to demonstrate the ability
to “slice” into the rendering and manipulate the viewpoint in realtime. This
clearly shows the dimensionality of the segmentation. </div><br></div>
</div>
    </div>
</div>
<div id="ctl00_MainContent_ctl00_divFooter" style="font-weight:bold">
    <div class="col-lg-5 col-md-5 col-sm-5">
        Proc. Intl. Soc. Mag. Reson. Med. 27 (2019)
    </div>
    <span id="ctl00_MainContent_ctl00_lblProgramNumber" class="col-7 col-md-7 col-sm-7">4720</span>
</div>


        </div>
    


</body></html>