<!DOCTYPE html>
<!-- saved from url=(0056)https://index.mirasmart.com/ISMRM2018/PDFfiles/3417.html -->
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><title>

</title>
     
    <script type="text/javascript" src="./3417_files/jquery.js.download"></script>
    

    <script src="./3417_files/MathJax.js.download" id=""></script>
    <link type="text/css" rel="stylesheet" href="./3417_files/css"><link type="text/css" rel="Stylesheet" href="./3417_files/bootstrap.min.css"><link type="text/css" rel="Stylesheet" href="./3417_files/bootstrap-theme.min.css"><link type="text/css" rel="Stylesheet" href="./3417_files/viewSubmissions.css"><meta name="viewport" content="width=device-width, initial-scale=1">  


    <script type="text/x-mathjax-config;executed=true">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$$$','$$$'], ["\\(","\\)"] ],
          processEscapes: true
        }
      });
    </script>

    
<style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style></head>
<body style=""><div id="MathJax_Message" style="display: none;"></div>
    
        <div id="SubmissionViewBreadCrumbWrapper"> </div>         
        <div id="contentWrapper" class="MainContentWrapper">   
           
    

	
    





<div class="col-lg-8 col-md-12 col-xm-12"> 
    <h3>
        <span id="ctl00_MainContent_ctl00_lblSubmissionID">3417</span>
    </h3>
    <span id="ctl00_MainContent_ctl00_submissionTitle" class="submissionTitle">Collaborative volumetric magnetic resonance image rendering on consumer-grade devices</span>
    <div id="ctl00_MainContent_ctl00_autherBlock">        
        <div id="ctl00_MainContent_ctl00_AuthorsAndAffiliationsBlock_divBlockContainer" class="AffiliationBlockContainer">
    <div id="affAuthers" class="affAuthers">Andrew Dupuis<sup>1,2</sup>, Dominique Franson<sup>1</sup>, Yun Jiang<sup>3</sup>, Jeff Mlakar<sup>2</sup>, Henry Eastman<sup>2</sup>, Vikas Gulani<sup>3</sup>, Nicole Seiberlich<sup>1</sup>, and Mark A. Griswold<sup>1,2,3</sup></div><i><div id="affOther" class="affOther"><br><sup>1</sup>Biomedical Engineering, Case Western Reserve University, Cleveland, OH, United States, <sup>2</sup>Interactive Commons, Case Western Reserve University, Cleveland, OH, United States, <sup>3</sup>Department of Radiology, School of Medicine, Case Western Reserve University, Cleveland, OH, United States</div></i>
</div>


    </div>

    <div id="ctl00_MainContent_ctl00_sectionsWrapper" class="sectionsWrapper">
	        
    <div class="divSectionBlock"><h3>Synopsis</h3><p class="synopsis">We
present a system for intra- or post-acquisition 3D rendering of
volumetric MRI datasets for independent or collaborative use on AR/VR and
mobile platforms. Consumer-grade head mounted displays, phones, and computers
are used to provide 3D visualizations. Datasets can be windowed and leveled in
the same manner as classic visualizations, and arbitrary slices can be selected
and viewed in real time in the context of the whole volume. Real world
dimensionality and spatialization is retained. Using this system, multiple
users can interact with a dataset collaboratively using current AR/VR platforms
or any modern cellphone, tablet, or laptop. </p></div><div class="divSectionBlock"><h3>Purpose</h3><p>

Medical
imaging traditionally relies on planar representations of patient data without
three-dimensional context. This is directly contrary to the reality of the
human body, where spatial information and feature dimensionality are of
critical importance to proper diagnosis and treatment. With the increasing
availability of high quality stereoscopic head mounted displays (HMDs) as well
as high performance non-stereoscopic mobile platforms, there exists a clear
opportunity to “re-spatialize” medical images to enable direct and intuitive
interaction both at the scanner and in the reading room.</p><p>Clinicians are
accustomed to collaboratively diagnosing patients through group inspection and
discussion. This process is impeded by traditional reading methods –
collaboratively evaluating scans by scrolling through a DICOM stack can’t
compare to physically searching for and pointing out anomalies. Moreover, a low
latency real-time multi-user 3D environment presented intra-acquisition using
AR, VR, or touchscreen offers a means of clinician engagement that better
approximates traditional diagnostic practice. We have therefore developed a
visualization pipeline to display both realtime and static MRI data on a group
of HMDs or mobile devices for collaborative viewing.</p></div><div class="divSectionBlock"><h3>Methods</h3><p>

Figure 1 details the rendering pipeline and approach.
Rendering clients could import data from offline-reconstructed DICOMs or
receive realtime-reconstructed data over TCP. 
Images were loaded into a volumetric texture system without compression,
allowing the user to manipulate image window and level at runtime. Voxel sizes
were calculated from scanner data to allow use of any isotropic or anisotropic
dataset. Rendering was accomplished by a progressive ray tracing (“raymarching”)
approach (1,2) described in Figure 1. Each voxel’s intensity value contributed to
the final screenspace pixel color via the raymarching graphics shader. Noise
was reduced using an adjustable noise floor filter (Figure 2). 

</p><p>In order to test the rendering pipeline’s accuracy, two offline magnetic
resonance datasets of the brain were acquired with 3D MP-RAGE sequence with
isotropic spatial resolution of  1mmx1mmx1mm,
and anisotropic resolution of  1.2mmx1.2mmx2mm.
The datasets were reconstructed offline to DICOMs and loaded onto client
systems. Initialization and framerate performance was evaluated on a Desktop PC
(3.2Ghz CPU, Quadro K4200 GPU), Oculus Gear VR (Samsung Galaxy S8+), and
Microsoft Hololens for multiple matrix sizes and raymarching step counts. These
devices represent, from highest to lowest, the three major performance tiers
for target devices. Lag in realtime transmission was tested over Gigabit
Ethernet and 802.11ac Wifi using single, 3-slice, and full volume updating of a
volumetric heart acquisition. (FLASH sequence w/ undersampled radial
trajectory, reconstructed using through-time radial GRAPPA on Gadgetron (3,4)).</p><p>Users were provided with runtime controls for window, level, position,
and orientation as well as slice plane position and orientation through
handheld controllers, gestures, or touchscreen interactions. The clipping
position could also be controlled by the user’s head to allow natural data
exploration. In multi-user use, render parameters were synchronized so users
shared the same visualization. Additional client-side rendering parameters
included raymarching step count and framerate-dependent downsampling to
maintain performance.</p><p>

Collaborative sessions were accomplished across all
tested platforms. A host device began a “reading session” which other client
devices could join. Hosts retained control of rendering parameters, while all
users could explore the rendering. Participants on 2D platforms could interact
via touchscreen, with a projection of their simulated “position” visualized in
the AR/VR “reading room” to enhance embodiment.

</p><p> </p></div><div class="divSectionBlock"><h3>Results</h3>Figure 2 is an animated GIF showing results from the
rending pipeline. It also demonstrates the noise rejection filter system in
use, enhancing isolation of useful data to improve the visualization. Figure 3
maps system initialization and render times versus matrix size and volume
rendering stepcount, as well as transmission lag in realtime use. Though
dwarfed by the Desktop PC, both mobile devices rendered standard 128^3 datasets
near full fidelity with minimal loading times. Single, three-slice, and
full-volume realtime updating all supported &gt;10fps transfer. Figure 4 is an
animated GIF demonstrating accurate rendering of isotropic and anisotropic
MP-RAGE datasets, dynamic clipping planes, and realtime intra-acquisition
updating of a rendered volume. Figure 5 is an animated gif of a collaborative
session utilizing the platform.</div><div class="divSectionBlock"><h3>Discussion</h3>Mixed Reality and mobile platforms offer highly flexible and
collaborative methods for displaying MR datasets in full context. All three
consumer-grade systems were capable of rendering standard matrix size isotropic
and anisotropic acquisitions at acceptable framerates for both static and
realtime acquisitions. Collaborative reading sessions of volumetric data sets
allowed multiple users to simultaneously interact with a dataset from
independent devices. This success indicates a need for further exploration of
the impact a platform-agnostic volumetric rendering system could have on
creating the three-dimensional collaborative reading rooms and interventional
suites of the future.</div><div class="divSectionBlock"><h3>Acknowledgements</h3>Siemens Healthcare, R01EB018108, NSF 1563805,
R01DK098503, and R01HL094557. </div><div class="divSectionBlock"><h3>References</h3><p>

1.
Levoy, M. Efﬁcient ray tracing of volume data. ACM Trans. Graph. 1990; 9, 3,
p.245–261
</p><p>
2.
Zhou et al. Real-time Smoke Rendering Using Compensated Raymarching. Microsoft
Research. 2007. </p><p>

3. Hansen MS,
Sørensen TS. Gadgetron: An open source framework for medical image
reconstruction.

Magn.
Reson. Med. 2013;69:1768–1776.</p><p>4.
Franson D, Ahad J, Hamilton J, Lo W, Jiang Y, Chen Y, Seiberlich N. Real-time
3D cardiac MRI using

through-time
radial GRAPPA and GPU-enabled reconstruction pipelines in the Gadgetron
framework. In:

Proc. Intl. Soc. Mag.
Reson. Med. 25.; 2017. p. 448. </p></div>
</div>
        
</div>
            
<div class="col-lg-3">
        <div id="ctl00_MainContent_ctl00_figures">
        <h3>Figures</h3>
        <div id="ctl00_MainContent_ctl00_figuresWrapper" class="figuresWrapper">
	
        
        <div class="divSectionBlock"><a id="ctl00_MainContent_ctl00_lnkImage_1" class="thumbnail" data-lightbox="figureImages" title="Input
to the rendering pipeline is a volumetric acquisition that is reconstructed in
realtime and transmitted over TCP, or reconstructed offline and saved to DICOM.
On the client, data is loaded into 2D floating point full precision arrays of
intensity values to retain bit depth. User-controlled window and level settings
are applied at runtime to rescale intensity values. Textures are converted to a
3D Volumetric texture in memory and assigned to a representative mesh that
controls rendering shape and allows dynamic slicing through the dataset.
Progressive raymarching is accomplished in using a custom Cg shader with
multiple pixel combination algorithms.&amp;nbsp;" href="https://index.mirasmart.com/ISMRM2018/PDFfiles/images/5370/ISMRM2018-005370_Fig1.png" target="_blank"><img src="./3417_files/ISMRM2018-005370_Fig1.png" border="0" style="text-align:center;"></a><div class="thumbnailCaptions">Input
to the rendering pipeline is a volumetric acquisition that is reconstructed in
realtime and transmitted over TCP, or reconstructed offline and saved to DICOM.
On the client, data is loaded into 2D floating point full precision arrays of
intensity values to retain bit depth. User-controlled window and level settings
are applied at runtime to rescale intensity values. Textures are converted to a
3D Volumetric texture in memory and assigned to a representative mesh that
controls rendering shape and allows dynamic slicing through the dataset.
Progressive raymarching is accomplished in using a custom Cg shader with
multiple pixel combination algorithms. </div><br><a id="ctl00_MainContent_ctl00_lnkImage_2" class="thumbnail" data-lightbox="figureImages" title="This animated GIF demonstrated the
user-adjustable noise rejection floor in use on an MP-RAGE brain scan in real
time. Noise is isolated in the raw data prior to window and level calculations
and tagged with zero opacity. During the rendering loop, the raymarching shader
then discards the tagged pixel and allows the non-noise patient data to
dominate the volumetric rendering calculations. This
process does not affect framerate performance.&amp;nbsp;" href="https://index.mirasmart.com/ISMRM2018/PDFfiles/images/5370/ISMRM2018-005370_Fig2.gif" target="_blank"><img src="./3417_files/ISMRM2018-005370_Fig2.gif" border="0" style="text-align:center;"></a><div class="thumbnailCaptions">This animated GIF demonstrated the
user-adjustable noise rejection floor in use on an MP-RAGE brain scan in real
time. Noise is isolated in the raw data prior to window and level calculations
and tagged with zero opacity. During the rendering loop, the raymarching shader
then discards the tagged pixel and allows the non-noise patient data to
dominate the volumetric rendering calculations. This
process does not affect framerate performance. </div><br><a id="ctl00_MainContent_ctl00_lnkImage_3" class="thumbnail" data-lightbox="figureImages" title="Loading times and raymarching performance are
dependent on a platform&amp;rsquo;s CPU and GPU characteristics respectively. Realtime
data transmission is dependent on communication medium. (A) Loading time is an
O(N) function of voxel count. A typical 128x128x128 matrix dataset is shown by
the grey line (B) Framerates on desktops were O(n) with raymarching steps,
while mobile platforms were less predictable due to forced GPU management and
VSync delays. (C) Transmission delays were tested over 1000 frames with a
128x128 matrix over (Ethernet, Wifi) while updating 1 slice (16.3&amp;plusmn;3.3ms,
21.2&amp;plusmn;4.8ms), 3 slices (22.3&amp;plusmn;3.4ms, 29.11&amp;plusmn;4.7ms), or the full volume (72.0&amp;plusmn;5.0ms, 93.8&amp;plusmn;10.93ms) each frame." href="https://index.mirasmart.com/ISMRM2018/PDFfiles/images/5370/ISMRM2018-005370_Fig3.PNG" target="_blank"><img src="./3417_files/ISMRM2018-005370_Fig3.PNG" border="0" style="text-align:center;"></a><div class="thumbnailCaptions">Loading times and raymarching performance are
dependent on a platform’s CPU and GPU characteristics respectively. Realtime
data transmission is dependent on communication medium. (A) Loading time is an
O(N) function of voxel count. A typical 128x128x128 matrix dataset is shown by
the grey line (B) Framerates on desktops were O(n) with raymarching steps,
while mobile platforms were less predictable due to forced GPU management and
VSync delays. (C) Transmission delays were tested over 1000 frames with a
128x128 matrix over (Ethernet, Wifi) while updating 1 slice (16.3±3.3ms,
21.2±4.8ms), 3 slices (22.3±3.4ms, 29.11±4.7ms), or the full volume (72.0±5.0ms, 93.8±10.93ms) each frame.</div><br><a id="ctl00_MainContent_ctl00_lnkImage_4" class="thumbnail" data-lightbox="figureImages" title="The top two animated GIFs display&amp;rsquo;s the
system&amp;rsquo;s ability to cope with both isotropic and anisotropic datasets without
introducing errors. The datasets were acquired with an MP-RAGE sequence on a
Siemens 3T scanner with 1.0mm isotropic and 1.2mmx1.2mmx2.0mm voxel sizes
respectively. The bottom left GIF demonstrates arbitrary clipping plane
selection. The bottom right GIF shows a FLASH sequence of the human heart
(reconstructed online using Gadgetron) dynamically updating the volume in real
time.&amp;nbsp;" href="https://index.mirasmart.com/ISMRM2018/PDFfiles/images/5370/ISMRM2018-005370_Fig4.gif" target="_blank"><img src="./3417_files/ISMRM2018-005370_Fig4.gif" border="0" style="text-align:center;"></a><div class="thumbnailCaptions">The top two animated GIFs display’s the
system’s ability to cope with both isotropic and anisotropic datasets without
introducing errors. The datasets were acquired with an MP-RAGE sequence on a
Siemens 3T scanner with 1.0mm isotropic and 1.2mmx1.2mmx2.0mm voxel sizes
respectively. The bottom left GIF demonstrates arbitrary clipping plane
selection. The bottom right GIF shows a FLASH sequence of the human heart
(reconstructed online using Gadgetron) dynamically updating the volume in real
time. </div><br><a id="ctl00_MainContent_ctl00_lnkImage_5" class="thumbnail" data-lightbox="figureImages" title="The above animated GIF demonstrates a multi-user
collaborative reading session using the volumetric system. The user in the
front right is dynamically controlling the clipping plane with their head
position, while the other users are able to engage independently while
remaining synced with the leader&amp;rsquo;s visualization parameters and clipping plane.
Here two Hololenses, an Oculus Rift, a Surface Tablet and a desktop pc are
sharing the same visualization. This recording was captured using a BevCam compositor system for Microsoft Hololens." href="https://index.mirasmart.com/ISMRM2018/PDFfiles/images/5370/ISMRM2018-005370_Fig5.gif" target="_blank"><img src="./3417_files/ISMRM2018-005370_Fig5.gif" border="0" style="text-align:center;"></a><div class="thumbnailCaptions">The above animated GIF demonstrates a multi-user
collaborative reading session using the volumetric system. The user in the
front right is dynamically controlling the clipping plane with their head
position, while the other users are able to engage independently while
remaining synced with the leader’s visualization parameters and clipping plane.
Here two Hololenses, an Oculus Rift, a Surface Tablet and a desktop pc are
sharing the same visualization. This recording was captured using a BevCam compositor system for Microsoft Hololens.</div><br></div>
</div>
    </div>
</div>
<div id="ctl00_MainContent_ctl00_divFooter" style="font-weight:bold">
    <div class="col-lg-5 col-md-5 col-sm-5">
        Proc. Intl. Soc. Mag. Reson. Med. 26 (2018)
    </div>
    <span id="ctl00_MainContent_ctl00_lblProgramNumber" class="col-7 col-md-7 col-sm-7">3417</span>
</div>


        </div>
    


</body></html>